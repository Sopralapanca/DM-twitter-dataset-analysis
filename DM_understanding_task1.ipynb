{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sopralapanca/TwitterDataset-DM-Project/blob/develop/DM_understanding_task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKlYZFkefEpD"
      },
      "source": [
        "# What will be done here...\n",
        "\n",
        "Following the suggestion given from the milestone description, the scope of this notebook is to get a first knowledge of the dataset, seeing the dimension of it and get hints on how to handle it correcty. To achive these scopes we will read the content of the columns and convert them in the right type, in the end we will propose some plots that contain first informations on how the data are distributed. \n",
        "\n",
        "A deeper analysis will be done after the cleaning and substitution of wrong rows in the next notebook **Data Preparation**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gQPukXcvQNl"
      },
      "source": [
        "Task 1.1: Data Understanding\n",
        "\n",
        "Explore the dataset with the analytical tools studied and write a concise “data understanding”\n",
        "report assessing data quality, the distribution of the variables and the pairwise correlations.\n",
        "Subtasks of DU:\n",
        "\n",
        "1. Data semantics for each feature that is not described above and the new one defined\n",
        "by the team\n",
        "2. Distribution of the variables and statistics\n",
        "3. Assessing data quality (missing values, outliers, duplicated records, errors)\n",
        "4. Variables transformations\n",
        "5. Pairwise correlations and eventual elimination of redundant variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WME54aQfZ7JU"
      },
      "source": [
        "# Import libraries and load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diSP3qH-3tE3"
      },
      "outputs": [],
      "source": [
        "!pip install calmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVTe-zFXLMMj"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "import math\n",
        "import calendar\n",
        "import calmap\n",
        "import os\n",
        "\n",
        "from os import path\n",
        "from sys import getsizeof"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_path = \"/data/tweets.csv\"\n",
        "user_path = \"/data/users.csv\"\n",
        "\n",
        "# max_rows is used to load a portion of the dataset\n",
        "\n",
        "max_rows = 0\n",
        " \n",
        "users_df = pd.read_csv(user_path) \n",
        "\n",
        "if max_rows != 0:\n",
        "  tweets_df = pd.read_csv(tweet_path, nrows=max_rows, encoding=\"UTF-8\")\n",
        "else:\n",
        "  tweets_df = pd.read_csv(tweet_path, encoding=\"UTF-8\")"
      ],
      "metadata": {
        "id": "X327tTh2trRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_rows is used to load a portion of the dataset\n",
        "\n",
        "max_rows = 0\n",
        " \n",
        "users_df = pd.read_csv(\"./users.csv\") \n",
        "\n",
        "if max_rows != 0:\n",
        "  tweets_df = pd.read_csv(\"./tweets.csv\", nrows=max_rows, encoding=\"UTF-8\")\n",
        "else:\n",
        "  tweets_df = pd.read_csv(\"./tweets.csv\", encoding=\"UTF-8\")"
      ],
      "metadata": {
        "id": "rks_69IsGB_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJrBnKPjeeB6"
      },
      "source": [
        "# **Data Understanding**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCSh7DQxaoBC"
      },
      "source": [
        "## Data Semantics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q-Z23rdpZf1"
      },
      "source": [
        "From the project specifications we have:\n",
        "\n",
        "USERS CSV\n",
        "\n",
        "1. User Id: an incremental identifier for the user\n",
        "2. Statues Count: the count of the tweets made by the user at the moment of data\n",
        "crawling (it is involving only the tweets)\n",
        "3. Lang: the user’s language selected, there are listed also slangs derived from the country\n",
        "4. Created at: the timestamp in which the profile was created, many dates are wrong\n",
        "5. Label: a binary variable that indicates if a user is a bot or a genuine user\n",
        "\n",
        "TWEETS CSV\n",
        "\n",
        "1. ID: an incremental identifier for the tweet, reply or comment\n",
        "2. User Id: a unique identifier for the user who wrote the tweet\n",
        "3. Retweet count: number of retweets for the tweet in analysis\n",
        "4. Reply count: number of reply for the tweet in analysis\n",
        "5. Favorite count: number of likes received \n",
        "6. Num hashtags: number of hashtags used in the tweet\n",
        "7. Num urls: number of urls in the tweet\n",
        "8. Num mentions: number of mentions in the tweet\n",
        "9. Created at: when the tweet was created, many are wrong\n",
        "10. Text: the text of the tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEm5rj6GLXvL"
      },
      "source": [
        "#### Tweet.csv informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLAMvZpArgnT"
      },
      "outputs": [],
      "source": [
        "tweets_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnCcLxlurr4k"
      },
      "outputs": [],
      "source": [
        "tweets_df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "typ0XGf6LdXT"
      },
      "source": [
        "#### User.csv informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8ZOd8gdPqZF"
      },
      "outputs": [],
      "source": [
        "users_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR-xDI7UPwqU"
      },
      "outputs": [],
      "source": [
        "users_df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1MajpyPK4P3"
      },
      "source": [
        "## Assessing data quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JFaVjjWMdnh"
      },
      "source": [
        "**Checking if there are any missing values and count them**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR7Cpqbx7VLJ"
      },
      "outputs": [],
      "source": [
        "def nan_unique_count(df: DataFrame):\n",
        "  print('| {:>15} | {:>15}| {:>15} |'.format(*[\"column\", \"unique values\", \"NaN\" ]))\n",
        "  print('------------------------------------------------------')\n",
        "  for col in df.columns:\n",
        "    print('| {:>15} | {:>15}| {:>15} |'.format(*[col, len(df[col].unique()), df[col].isna().sum() ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ayY6ARqMxop"
      },
      "outputs": [],
      "source": [
        "nan_unique_count(tweets_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E1USBeeNz3P"
      },
      "outputs": [],
      "source": [
        "nan_unique_count(users_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEx6HBacgTV0"
      },
      "source": [
        "As shown above there are some null values inside the two dataframes. In addition, the info method of pandas gives us information about the type of attributes in the dataframe. As you can see all the features in the tweets dataframe are of type \"object\" this means that non-numeric values are present in attributes that should be numbers such as id, user_id and so on. The data is therefore to be cleaned and properly transformed to the right type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyhrCOWVCtPI"
      },
      "source": [
        "**Anomalies on numeric fields**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPUs4Ack2wNW"
      },
      "outputs": [],
      "source": [
        "# to check if non-numeric values are present in the dataset  \n",
        "# we throw an exception when we try to convert the feature to the correct type.\n",
        "\n",
        "tweets_cols = [\"id\", \"user_id\", \"retweet_count\", \"reply_count\",\n",
        "           \"favorite_count\", \"num_hashtags\",  \"num_urls\", \"num_mentions\"]\n",
        "\n",
        "user_cols = [\"id\", \"statuses_count\"]\n",
        "\n",
        "# checking non-numeric values inside tweets df\n",
        "for col in tweets_cols:\n",
        "    try:\n",
        "        pd.to_numeric(tweets_df[col], errors='raise')\n",
        "    except Exception as e:\n",
        "      print(f\"column: {col} error: {e}\")\n",
        "\n",
        "# checking non-numeric values inside users df\n",
        "for col in user_cols:\n",
        "    try:\n",
        "        pd.to_numeric(users_df[col], errors='raise')\n",
        "    except Exception as e:\n",
        "      print(f\"column: {col} error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count non-numeric values on tweets dataframe\n",
        "\n",
        "for col in tweets_cols:\n",
        "  mask = pd.to_numeric(tweets_df[col], errors='coerce').isna()\n",
        "  a = mask.sum()\n",
        "\n",
        "  print(f\"column {col} has {a} non-numeric values\")\n",
        "\n",
        "del mask"
      ],
      "metadata": {
        "id": "-ulVXi0dNM5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--IFdjKwCzHK"
      },
      "source": [
        "**Anomalies on datetime**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pFNrYQA_NY_"
      },
      "outputs": [],
      "source": [
        "# checking correct datetime in tweets df and user df\n",
        "\n",
        "try:\n",
        "  pd.to_datetime(tweets_df[\"created_at\"], errors='raise')\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "try:\n",
        "  pd.to_datetime(users_df[\"created_at\"], errors='raise')\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEvPP8-AJHpa"
      },
      "source": [
        "no error in datetime format has been found"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H_sK07VDXqq"
      },
      "source": [
        "**Anomalies on languages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJV51VqmDmnl"
      },
      "outputs": [],
      "source": [
        "print(users_df[\"lang\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hodT_jhT0-s"
      },
      "source": [
        "We can immediately notice erroneous values such as \"Select Language...\" or the repetition of \"zh-tw/zh-TW\". These values will be cleaned in the data cleaning section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeGkXEISh6Ua"
      },
      "outputs": [],
      "source": [
        "users_df.loc[users_df['lang'] == 'Select Language...']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_vA3AuBEOjh"
      },
      "outputs": [],
      "source": [
        "tweets_df.loc[tweets_df['user_id'] == '2956613720'].head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SfioJbGiHN0"
      },
      "outputs": [],
      "source": [
        "tweets_df.loc[tweets_df['user_id'] == '2904858613'].head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQLYUr-uig6B"
      },
      "outputs": [],
      "source": [
        "users_df.loc[users_df['lang'] == 'xx-lc']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qncTrcygiv7F"
      },
      "outputs": [],
      "source": [
        "tweets_df.loc[tweets_df['user_id'] == '29552151'].head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can state that the erroneous languages are from users that writes english tweets"
      ],
      "metadata": {
        "id": "sgHhSh17t730"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anomalies on user id**"
      ],
      "metadata": {
        "id": "kySJQYSNlJOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQXKSVIhWVIf"
      },
      "outputs": [],
      "source": [
        "# check if there are duplicated ids on users dataframe\n",
        "users_df[users_df['id'].duplicated() & users_df['id'].notnull()][\"id\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No duplicated ids found"
      ],
      "metadata": {
        "id": "2kYHwcndleiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anomalies on bot label**"
      ],
      "metadata": {
        "id": "fRnDl4tslmnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the column is binary\n",
        "print(users_df['bot'].isin([0,1]).all())"
      ],
      "metadata": {
        "id": "5dMnjGwMltRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrx0IF1KSl1S"
      },
      "source": [
        "## Assigning correct type to attribute"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_ssize = getsizeof(tweets_df)/(1024.0**3)\n",
        "user_ssize = getsizeof(users_df)/(1024.0**2)\n",
        "print(\"Tweets Dataframe specifics : ------------- \\n{} - size: {:.2f} GB\\n\".format(tweets_df.dtypes, tweets_ssize))\n",
        "print(\"Users Dataframe specifics:------------- \\n{} - size: {:.2f} MB\".format(users_df.dtypes, user_ssize))"
      ],
      "metadata": {
        "id": "_Y3uB_7RES_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the binary variables in boolean"
      ],
      "metadata": {
        "id": "_SjxDsJaGZLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_df['bot'] = users_df['bot'].apply(lambda x: x==1)  "
      ],
      "metadata": {
        "id": "bu_WUYYpGS65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning to date columns the appropriate typo"
      ],
      "metadata": {
        "id": "oDWSRzuwISAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df[\"created_at\"]=pd.to_datetime(tweets_df[\"created_at\"]\n",
        "                                       , errors='coerce', yearfirst=True)\n",
        "\n",
        "users_df[\"created_at\"]=pd.to_datetime(users_df[\"created_at\"]\n",
        "                                      , errors='coerce', yearfirst=True)"
      ],
      "metadata": {
        "id": "EOY8JTYgIXIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform the numeric and text columns in the smallest integer/float type that fits the values and relatively string, in order to save further memory this process can be repeated after the outlier handling."
      ],
      "metadata": {
        "id": "3-FCvSvxI1ak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGNGeJwcMLVH"
      },
      "outputs": [],
      "source": [
        "# If a value can't be converted to integer a NaN is inserted\n",
        "# The NaN will be replaced later\n",
        "\n",
        "numeric_columns = [\"id\", \"user_id\", \"retweet_count\", \n",
        "                   \"reply_count\", \"favorite_count\", \"num_hashtags\",  \n",
        "                   \"num_urls\", \"num_mentions\"]\n",
        "\n",
        "for col in numeric_columns:\n",
        "    tweets_df[col] = pd.to_numeric(tweets_df[col], \n",
        "                                   errors='coerce', downcast='integer')\n",
        "\n",
        "users_df['statuses_count'] = pd.to_numeric(users_df['statuses_count'], \n",
        "                                           errors='coerce', downcast='integer')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the text columns in string"
      ],
      "metadata": {
        "id": "EO-muv0pJ_NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df['text'] = tweets_df['text'].astype('string')\n",
        "\n",
        "users_df['name'] = users_df['name'].astype('string')\n",
        "users_df['lang'] = users_df['lang'].astype('string')"
      ],
      "metadata": {
        "id": "L7AdGCRMJoj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if all the operations are been performed correctly and how much space we have saved."
      ],
      "metadata": {
        "id": "3PPm6GuELyCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_esize = getsizeof(tweets_df)/(1024.0**3)\n",
        "user_esize = getsizeof(users_df)/(1024.0**2)\n",
        "print(\"Tweets Dataframe specifics : ------------- \\n{} - size: {:.2f} GB\\n|||||| SAVED SPACE: {:.1f}% ||||||\\n\".format(tweets_df.dtypes, tweets_esize, (1-tweets_esize/tweets_ssize)*100))\n",
        "print(\"Users Dataframe specifics:------------- \\n{} - size: {:.2f} MB\\n|||||| SAVED SPACE: {:.1f}% ||||||\".format(users_df.dtypes, user_esize, (1-user_esize/user_ssize)*100))"
      ],
      "metadata": {
        "id": "SoMNUV8IRKoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.describe()"
      ],
      "metadata": {
        "id": "u83AawNjnCv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjaoibC9Uu0s"
      },
      "outputs": [],
      "source": [
        "tweets_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using pandas' describe method, we can see simple statistics on dataframes. As can be seen in the tweets dataset, there are very large values such as inf and negative values, so we can say that in those columns there is the presence of outliers. \n",
        "In the section \"Visualising data distributions\" we will provide more statistics."
      ],
      "metadata": {
        "id": "F3tvWuLCnRLf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgRdQx9RSizI"
      },
      "source": [
        "## Visualizing data distributions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9YDlhEnSsyC"
      },
      "source": [
        "In this section we will show the distribution of the data by displaying different plots for various features in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "color=['#12a0d7']"
      ],
      "metadata": {
        "id": "Q2RCeAyTrHPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tweets dataset"
      ],
      "metadata": {
        "id": "b4RFj1eDqTp_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWExOxPPhQoU"
      },
      "source": [
        "Substitute inf values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38ODp91Nc2lL"
      },
      "outputs": [],
      "source": [
        "# we substitute inf values with NaN  in order to compute some plots and later we compute the mean\n",
        "tweets_df.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data distribution of numerical fields**"
      ],
      "metadata": {
        "id": "_liTRo4vsdkO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIX_ADieVmH4"
      },
      "outputs": [],
      "source": [
        "def multiple_histograms(df: DataFrame, columns):\n",
        "  fig, axs = plt.subplots(2, 3, sharex=False, sharey=False, dpi=80)\n",
        "  idx_col = 0\n",
        "\n",
        "  for i in range(2):\n",
        "    for j in range(3):\n",
        "\n",
        "      col = columns[idx_col]\n",
        "      idx_col +=1\n",
        "      \n",
        "      ax = tweets_df[col].plot.hist(bins=6, logy=True,\n",
        "                                    align='mid',title=col,\n",
        "                                    grid=True,figsize=(20,10),\n",
        "                                    ax = axs[i, j], color=color)\n",
        "\n",
        "      ax.grid(axis='both', alpha=0.5, linestyle='--')\n",
        "   \n",
        "      \n",
        "columns = [\"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\",  \"num_urls\", \"num_mentions\"] \n",
        "\n",
        "multiple_histograms(tweets_df, columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the scale the number differ in width till a scale of 10^210, but for only few tweets. This can be read as a clear mark of rows outside the normal distribution."
      ],
      "metadata": {
        "id": "fsRKEWHSb-LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\",  \"num_urls\", \"num_mentions\"] \n",
        "\n",
        "f, ax = plt.subplots(figsize=(20, 7))\n",
        "sns.boxplot(data=tweets_df[columns], orient=\"h\")\n",
        "# Tweak the visual presentation\n",
        "ax.xaxis.grid(True)\n",
        "ax.grid(axis='both', alpha=0.5, linestyle='--')\n",
        "ax.set_xlim(-1000, 1000000)\n",
        "sns.despine(trim=True, left=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z84ymyuIaipH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_boxplots(df: DataFrame, columns):\n",
        "  fig, axs = plt.subplots(2, 3, sharex=False, sharey=False, dpi=80)\n",
        "  fig.set_size_inches(20, 10)\n",
        "  idx_col = 0\n",
        "\n",
        "  for i in range(2):\n",
        "    for j in range(3):\n",
        "\n",
        "      col = columns[idx_col]\n",
        "      idx_col +=1\n",
        "\n",
        "      ax = tweets_df[col].plot.box(showmeans=True, \n",
        "                              grid=True, ax = axs[i, j])\n",
        "      ax.set_ylim(-10, 1000000)\n",
        "\n",
        "\n",
        "      ax.grid(axis='both', alpha=0.5, linestyle='--')\n",
        "   \n",
        "      \n",
        "columns = [\"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\",  \"num_urls\", \"num_mentions\"] \n",
        "\n",
        "multiple_boxplots(tweets_df, columns=columns)"
      ],
      "metadata": {
        "id": "PoduNmJ7cdBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the boxplots above there are many values collapsed in dense areas, than there are very high values that will be dealt with, mantaining the significative informations, in such a way that we can have the focus in the right spots."
      ],
      "metadata": {
        "id": "cQX9kyx4nHef"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwwmI2ZW1GHn"
      },
      "source": [
        "**Distribution of created_at**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRKnYhLD1FEr"
      },
      "outputs": [],
      "source": [
        "years = tweets_df['created_at'].dt.year\n",
        "years.value_counts().sort_index().plot(kind=\"bar\", logy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjssWqfMBujp"
      },
      "source": [
        "As we can see from the plot, there are multiple non sense dates of tweets since there are dates that correspond to tweets when twitter had not yet been created and dates in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rutMimouOmXa"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "f, ax = plt.subplots(figsize=(7, 8))\n",
        "sns.despine(f)\n",
        "\n",
        "# Create the histogram setting the column to be represented and the one to overlap\n",
        "g = sns.histplot(\n",
        "    tweets_df,\n",
        "    x=tweets_df['created_at'].dt.month, hue=tweets_df['created_at'].dt.year,\n",
        "    multiple='layer',\n",
        "    log_scale=[False, True],\n",
        "    discrete=True,\n",
        "    palette='husl'\n",
        ")\n",
        "\n",
        "# Tweak the visual presentation\n",
        "ax.xaxis.set_major_formatter(mpl.ticker.ScalarFormatter())\n",
        "ax.set_xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "ax.set_xlabel('Months')\n",
        "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1), title='Year')\n",
        "ax.set_xticklabels([month for month in calendar.month_name[1:]],\n",
        "                    fontdict={'horizontalalignment': 'center', 'fontsize': 12, 'rotation': 30})\n",
        "plt.show()\n",
        "\n",
        "del g, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see all the years tweets distribution over same months"
      ],
      "metadata": {
        "id": "Bk56F5rhP2sp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC3BcENdJJpI"
      },
      "outputs": [],
      "source": [
        "today = pd.to_datetime(\"today\")     # we set today since there are no tweets later than 2020 with meaningful\n",
        "twitter_birth = pd.to_datetime(\"2006-03-21\")\n",
        "\n",
        "mask_datesOK = (tweets_df['created_at'] < today) & (tweets_df['created_at'] > twitter_birth)  \n",
        "  \n",
        "print(\"Number of tweets with a not coherent date: \", len(tweets_df[~mask_datesOK]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVsivtBd2Ilc"
      },
      "source": [
        "**Distribution of lenght of tweets**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X97lGfBiRTAT"
      },
      "outputs": [],
      "source": [
        "ax = tweets_df['text'].str.len().plot.hist(bins=30, logy=True, \n",
        "                                           align='mid',\n",
        "                                           figsize=(10,6), grid=True)\n",
        "ax.set_xlabel(\"Length\")\n",
        "\n",
        "ax.grid(axis='both', alpha=0.5, linestyle='--')\n",
        "xticks = np.arange(0, 430, 15)\n",
        "ax.set_xticks(xticks)\n",
        "ax.tick_params(axis='x', labelrotation=-90)\n",
        "plt.show()\n",
        "del ax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of the tweets based on the IDs**"
      ],
      "metadata": {
        "id": "0lqbo5N3Edcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax1 = tweets_df[mask_datesOK].plot.scatter(x='created_at', y='id', c=color, s=0.1)\n",
        "plt.show()\n",
        "del ax1"
      ],
      "metadata": {
        "id": "fjGsBHaLGOuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we do a zoom for the tweets with the correct dates in order to estrapolate some sort of correlation between IDs and dates. As we can see there is more density with the growth of the ID in late dates."
      ],
      "metadata": {
        "id": "dpPkp4VdIzNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Users dataset"
      ],
      "metadata": {
        "id": "KooRz5mOtsDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of created_at**"
      ],
      "metadata": {
        "id": "LbPfBpgFPdUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "f, ax = plt.subplots(figsize=(7, 8))\n",
        "sns.despine(f)\n",
        "\n",
        "\n",
        "# Create the histogram setting the column to be represented and the one to overlap\n",
        "g = sns.histplot(\n",
        "    tweets_df,\n",
        "    x=users_df['created_at'].dt.month, hue=users_df['created_at'].dt.year,\n",
        "    multiple='layer',\n",
        "    log_scale=[False, True],\n",
        "    discrete=True,\n",
        "    palette='husl'\n",
        ")\n",
        "\n",
        "# Tweak the visual presentation\n",
        "ax.xaxis.set_major_formatter(mpl.ticker.ScalarFormatter())\n",
        "ax.set_xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "ax.set_xlabel('Months')\n",
        "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1), title='Year')\n",
        "ax.set_xticklabels([month for month in calendar.month_name[1:]],\n",
        "                    fontdict={'horizontalalignment': 'center', 'fontsize': 12, 'rotation': 30})\n",
        "plt.show()\n",
        "\n",
        "del g, ax"
      ],
      "metadata": {
        "id": "hkNAZnSxYKyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of statuses count**"
      ],
      "metadata": {
        "id": "jMfOH5E3wJLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = users_df['statuses_count'].plot.hist(bins=30, logy=True, \n",
        "                                           align='mid',title=\"Histogram of statuses_count\",\n",
        "                                           figsize=(10,6), grid=True)\n",
        "\n",
        "\n",
        "ax.grid(axis='both', alpha=0.5, linestyle='--')\n",
        "\n",
        "del ax"
      ],
      "metadata": {
        "id": "upFmciJ9wMtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdrGhn4Xsm41"
      },
      "source": [
        "## Visualizing data distributions by differentiating bots and non-bots.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZsrREEYUbRw"
      },
      "source": [
        "### Languages of actual users and bot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "f, ax = plt.subplots(figsize=(15, 5))\n",
        "sns.despine(f)\n",
        "\n",
        "sns.histplot(\n",
        "    users_df,\n",
        "    x='lang', hue='bot',\n",
        "    multiple=\"stack\",\n",
        "    palette=sns.color_palette(\"pastel\",2),\n",
        "    edgecolor=\".7\",\n",
        "    log_scale = [False, True],\n",
        "    linewidth=.5,\n",
        "    stat='count',\n",
        ").set(title='Differences in the amount of tweets written by bots & non per lang')\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.set_xlabel(\"Language\")\n",
        "ax.grid(axis='both', alpha=0.5, linestyle='--')\n",
        "ax.set_xticklabels([lang for lang in users_df['lang'].unique()],\n",
        "                    fontdict={'horizontalalignment': 'center', 'fontsize': 12, 'rotation': 90})\n",
        "plt.show()\n",
        "\n",
        "del f, ax"
      ],
      "metadata": {
        "id": "4WrHdEl70pRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPsGasjeTHpR"
      },
      "source": [
        "### Percentage of the number of user: Bot vs No-Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNtVmDsCTfsO"
      },
      "outputs": [],
      "source": [
        "bots = users_df[users_df['bot'] == 1]\n",
        "non_bots = users_df[users_df['bot'] == 0]\n",
        "labels = 'Bots', 'Non-Bots'\n",
        "sizes = [len(bots), len(non_bots)]\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t88mUSHp0gko"
      },
      "source": [
        "### Percentage of the number of tweet :  Bot vs No-Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nCsUjJX0hzR"
      },
      "outputs": [],
      "source": [
        "bots = users_df[users_df['bot'] == 1]\n",
        "non_bots = users_df[users_df['bot'] == 0]\n",
        "\n",
        "bots_ids = bots['id'].to_list()\n",
        "tweets_of_bots = tweets_df[tweets_df['user_id'].isin(bots_ids)]\n",
        "\n",
        "non_bots_ids = non_bots['id'].to_list()\n",
        "tweets_of_non_bots = tweets_df[tweets_df['user_id'].isin(non_bots_ids)]\n",
        "\n",
        "labels = 'Bots', 'Non-Bots'\n",
        "sizes = [len(tweets_of_bots), len(tweets_of_non_bots)]\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How long are the tweets written by the bots & non-bots?"
      ],
      "metadata": {
        "id": "0dcsw19vtUpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bot_mask = users_df['bot'] == True\n",
        "tweets_by_bot = tweets_df\n",
        "tweets_by_bot['bot'] = tweets_df['user_id'].isin(users_df[bot_mask]['id'])\n",
        "\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "f, ax = plt.subplots(figsize=(7, 5))\n",
        "sns.despine(f)\n",
        "\n",
        "sns.histplot(\n",
        "    tweets_by_bot,\n",
        "    x=tweets_by_bot['text'].str.len(), hue='bot',\n",
        "    multiple=\"stack\",\n",
        "    palette=sns.color_palette(\"pastel\",2),\n",
        "    edgecolor=\".7\",\n",
        "    log_scale = [False, True],\n",
        "    linewidth=.5,\n",
        "    stat='count',\n",
        "    binwidth=15,\n",
        "    binrange=[0, 430],\n",
        ")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.set_xlabel(\"Length\")\n",
        "xticks = np.arange(0, 430, 15)\n",
        "ax.set_xticks(xticks)\n",
        "ax.grid(axis='both', alpha=0.5, linestyle='--')\n",
        "ax.tick_params(axis='x', labelrotation=90)\n",
        "plt.show()\n",
        "\n",
        "del f, ax"
      ],
      "metadata": {
        "id": "Bbzvzmi9w5hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWIJzSnlU0Hm"
      },
      "source": [
        "### When were the bots created (years)?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "f, ax = plt.subplots(figsize=(7, 5))\n",
        "sns.despine(f)\n",
        "\n",
        "sns.histplot(\n",
        "    users_df,\n",
        "    x=users_df['created_at'].dt.year, hue='bot',\n",
        "    multiple=\"stack\",\n",
        "    palette=sns.color_palette(\"pastel\",2),\n",
        "    edgecolor=\".7\",\n",
        "    log_scale = [False, False],\n",
        "    linewidth=.5,\n",
        "    stat='count',\n",
        ")\n",
        "ax.set_ylabel(\"Counts\")\n",
        "ax.set_xlabel(\"\")\n",
        "ax.grid(axis='both', alpha=0.5, linestyle='')\n",
        "ax.tick_params(axis='x', labelrotation=30)\n",
        "plt.show()\n",
        "\n",
        "del f, ax"
      ],
      "metadata": {
        "id": "-_yp86qWZ0jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calendar Heatmaps\n",
        "\n",
        "Here there are plots showing how much sparse the data are in the years, as we can see most of the days have few tweets compared with the spikes in late 2019 and early 2020."
      ],
      "metadata": {
        "id": "4PtWnmqFrUgj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUTvyqALugRX"
      },
      "source": [
        "Calendar heatmap of tweets wrote by bots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4bjahJj1vUk"
      },
      "outputs": [],
      "source": [
        "bots = users_df[users_df['bot'] == True]\n",
        "bots_id = bots['id'].to_list()\n",
        "bots_tweets_df = tweets_df[tweets_df['user_id'].isin(bots_id)]\n",
        "events = bots_tweets_df['created_at'].value_counts()\n",
        "\n",
        "calmap.calendarplot(events, monthticks=3, daylabels='MTWTFSS',\n",
        "                    dayticks=[0, 2, 4, 6], cmap='YlGn',\n",
        "                    fillcolor='grey', \n",
        "                    linewidth=1.5,\n",
        "                    fig_kws=dict(figsize=(30, 20)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlEFMjMG38i7"
      },
      "source": [
        "Calendar heatmap of tweets wrote by non-bots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYEZf_3k4BuK"
      },
      "outputs": [],
      "source": [
        "bots = users_df[users_df['bot'] == False]\n",
        "bots_id = bots['id'].to_list()\n",
        "bots_tweets_df = tweets_df[tweets_df['user_id'].isin(bots_id)]\n",
        "events = bots_tweets_df['created_at'].value_counts()\n",
        "\n",
        "calmap.calendarplot(events, monthticks=3, daylabels='MTWTFSS',\n",
        "                    dayticks=[0, 2, 4, 6], cmap='YlGn',\n",
        "                    fillcolor='grey', \n",
        "                    linewidth=1.5,\n",
        "                    fig_kws=dict(figsize=(30, 50)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro-Tyk154i5I"
      },
      "source": [
        "Calendar heatmap of creation of bots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrCcnkcy4h6E"
      },
      "outputs": [],
      "source": [
        "bots = users_df[users_df['bot'] == True]\n",
        "events = bots['created_at'].value_counts()\n",
        "\n",
        "calmap.calendarplot(events, monthticks=3, daylabels='MTWTFSS',\n",
        "                    dayticks=[0, 2, 4, 6], cmap='YlGn',\n",
        "                    fillcolor='grey', \n",
        "                    linewidth=1.5, \n",
        "                    fig_kws=dict(figsize=(30, 20)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSND8p6M4xzU"
      },
      "source": [
        "Calendar heatmap of creation of non-bots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc6IiX2-4w07"
      },
      "outputs": [],
      "source": [
        "non_bots = users_df[users_df['bot'] == False]\n",
        "events = non_bots['created_at'].value_counts()\n",
        "\n",
        "calmap.calendarplot(events, monthticks=3, daylabels='MTWTFSS',\n",
        "                    dayticks=[0, 2, 4, 6], cmap='YlGn',\n",
        "                    fillcolor='grey', \n",
        "                    linewidth=1.5,\n",
        "                    fig_kws=dict(figsize=(30, 20)))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "x1MajpyPK4P3",
        "4PtWnmqFrUgj"
      ],
      "provenance": [],
      "toc_visible": true,
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}